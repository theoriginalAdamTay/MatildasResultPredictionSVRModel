{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Matildas Result Prediction SVR Model <i>(June/July 2025 Update)</i></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function of the model</h3>\n",
    "<p>This is an updated version of the regression model built using a support vector machine to predict the outcome of the Australian women's national football team's future matches, given all home and away results over the past five years (2020 through June 2nd, 2025).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model training code with explanations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Carry out imports of required libraries providing functionality:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Read home and away win-loss data over the past 5 years from Excel files, and concatenate separate data files together:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data = pd.read_excel('matildas_winlossHomeJuneJuly2025Update.xlsx')\n",
    "away_data = pd.read_excel('matildas_winlossAwayApril2025Update.xlsx')\n",
    "\n",
    "home_data['location'] = 'Home'\n",
    "away_data['location'] = 'Away'\n",
    "\n",
    "data = pd.concat([home_data, away_data], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Aggregate a binary result value based on Boolean values in dataset, where 1 corresponds to a win, 0.5 to a draw and 0 to a loss:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['result'] = data['win'] * 1 + data['draw'] * 0.5 + data['lose'] * 0\n",
    "data = data.drop(['win', 'draw', 'lose'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Define the features and target variables in the given dataset:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['home_team', 'away_team', 'home_score', 'away_score', 'tournament', 'city', 'country', 'location']]\n",
    "target = data['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Define two variables, <b>num_features</b> and <b>cat_features</b>, corresponding to quantitative and qualitative data respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['home_score', 'away_score']\n",
    "cat_features = ['home_team', 'away_team', 'tournament', 'city', 'country', 'location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Carry out preprocessing of the data using the StandardScaler and OneHotEncoder methods:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown = 'ignore', drop = 'first'), cat_features)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Define a Pipeline which carries out preprocessing and linear regression using a support vector machine:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', SVR(kernel = 'linear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Split the dataset into training and test sets with test set size 0.2 and random state 42:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Fit the pipeline to the training set data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Get predicted data from the test set data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Code for outputting prediction results with explanations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Define dataframe for future matches to predict, corresponding to the upcoming Matildas fixtures as of the June/July 2025 update:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_team = 'Australia'\n",
    "away_teams = ['Slovenia', 'Slovenia', 'Panama', 'Panama']\n",
    "cities = ['Perth', 'Perth', 'Bunbury', 'Perth']\n",
    "country = 'Australia'\n",
    "tournament = 'Friendly'\n",
    "venues = ['HBF Park', 'HBF Park', 'Hands Oval', 'HBF Park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_matches = pd.DataFrame({\n",
    "    'home_team': [home_team] * 4,\n",
    "    'away_team': away_teams,\n",
    "    'tournament': [tournament] * 4,\n",
    "    'city': cities,\n",
    "    'country': [country] * 4,\n",
    "    'location': venues,\n",
    "    'home_score': [0] * 4,\n",
    "    'away_score': [0] * 4\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Get predicted results from the prediction model and apply to future matches:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results = pipeline.predict(future_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add raw prediction data as a column to the resultant dataframe:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_matches['raw_predictiondata'] = predicted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Define a function for classification of predicted results based on raw prediction data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_result(predicted):\n",
    "    if predicted > 1.0:\n",
    "        return 'Win'\n",
    "    elif predicted < 1.0:\n",
    "        return 'Lose'\n",
    "    else:\n",
    "        return 'Draw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add new column to resultant dataframe with classified result corresponding to win, draw and loss outcomes:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_matches['predicted_result'] = future_matches['raw_predictiondata'].apply(classify_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Remove home and away score columns from the resultant dataframe, and output the data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_matches = future_matches.drop(columns = ['home_score', 'away_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resultant dataframe output</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is the resultant dataframe with predicted data, giving information about upcoming matches for the Australian women's national football team and their predicted outcomes as of the June/July 2025 update.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<h3>Explanation of columns</h3>\n",
    "<ul>\n",
    "    <li><b>home_team</b> corresponds to the designated home team for the match.</li>\n",
    "    <li><b>away_team</b> corresponds to the designated away team for the match.</li>\n",
    "    <li><b>tournament</b> corresponds to the tournament the fixtures are part of, or whether the fixtures are friendly matches.</li>\n",
    "    <li><b>city</b> corresponds to the city the match is being played in.</li>\n",
    "    <li><b>country</b> corresponds to the country the match is being played in.</li>\n",
    "    <li><b>location</b> corresponds to the stadium the match is being played at.</li>\n",
    "    <li><b>raw_predictiondata</b> corresponds to the raw prediction data output from the prediction model as a floating point number.</li>\n",
    "    <li><b>predicted_result</b> corresponds to the predicted outcome of the match based on the raw prediction data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation of the model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mean absolute error</h3>\n",
    "<p>This corresponds to the average absolute difference between predicted values and actual values, giving an idea of how wrong predictions are on average.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean absolute error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mean squared error</h3>\n",
    "<p>This corresponds to the average of the squares of errors, giving more weight to larger errors which makes it susceptible to being affected by outlying data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean squared error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Root mean squared error</h3>\n",
    "<p>This corresponds to the square root of the mean squared error, which provides the error in the same units as the raw prediction data to facilitate easier interpretation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(\"Root mean squared error:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>R-squared value</h3>\n",
    "<p>This corresponds to how well a model's performance in terms of predicting target variables based on its inputs is. In this case, this refers to variance in predicted outcomes based on the raw prediction data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared value:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accuracy</h3>\n",
    "<p>This corresponds to how accurate the overall model is.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "accuracy = (y_pred_binary == y_test).mean()\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
